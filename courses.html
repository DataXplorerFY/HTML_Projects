<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PIAIC Courses</title>
    <style>
        *{
            margin: 0;
            padding: 0;
        }
        ul li{
            background-color: black;
            color: white;
        }
        header{
            display: inline;
        }
        body{
            background-color: gray;
            color: black;
        }
    </style>
</head>

<body>
    <header>
        <nav>
            <ul>
                <li>Home</li>
                <li>About</li>
                <li>Contact</li>
                <li>Services</li>
            </ul>
        </nav>
    </header>



























    <h1>PIAIC Offers The Following Courses</h1>
    <ol>
        <li><a href="#ai">Artificial-inteligence</a></li>
        <li><a href="#bc">BlockChain</a></li>
        <li><a href="#cc">Cloud Computing</a></li>
        <li><a href="#iot">Internet Of Things</a></li> 
        <li><a href="#meta">MetaVerse</a></li>
    </ol>
    <br>
    <h2 id="ai">Artificial-inteligence</h2>
    <p>
        Artificial intelligence (AI), the ability of a digital computer or computer-controlled robot to perform tasks
        commonly associated with intelligent beings. The term is frequently applied to the project of developing systems
        endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover
        meaning, generalize, or learn from past experience. Since the development of the digital computer in the 1940s,
        it has been demonstrated that computers can be programmed to carry out very complex tasks—such as discovering
        proofs for mathematical theorems or playing chess—with great proficiency. Still, despite continuing advances in
        computer processing speed and memory capacity, there are as yet no programs that can match full human
        flexibility over wider domains or in tasks requiring much everyday knowledge. On the other hand, some programs
        have attained the performance levels of human experts and professionals in performing certain specific tasks, so
        that artificial intelligence in this limited sense is found in applications as diverse as medical diagnosis,
        computer search engines, voice or handwriting recognition, and chatbots.
        <br>
        All but the simplest human behaviour is ascribed to intelligence, while even the most complicated insect
        behaviour is usually not taken as an indication of intelligence. What is the difference? Consider the behaviour
        of the digger wasp, Sphex ichneumoneus. When the female wasp returns to her burrow with food, she first deposits
        it on the threshold, checks for intruders inside her burrow, and only then, if the coast is clear, carries her
        food inside. The real nature of the wasps instinctual behaviour is revealed if the food is moved a few inches
        away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as
        often as the food is displaced. Intelligence—conspicuously absent in the case of Sphex—must include the ability
        to adapt to new circumstances.
    </p>

    <h2 id="bc">BlockChain</h2>
    <p>
        In a few words, a blockchain is a digital ever-growing list of data records. Such a list is comprised of many
        blocks of data, which are organized in chronological order and are linked and secured by cryptographic proofs.
        The first prototype of a blockchain is dated back to the early 1990s when computer scientist Stuart Haber and
        physicist W. Scott Stornetta applied cryptographic techniques in a chain of blocks as a way to secure digital
        documents from data tampering. The work of Haber and Stornetta certainly inspired the work of Dave Bayer, Hal
        Finney, and many other computer scientists and cryptography enthusiasts - which eventually lead to the creation
        of Bitcoin, as the first decentralized electronic cash system (or simply the first cryptocurrency). The Bitcoin
        whitepaper was published in 2008 under the pseudonym Satoshi Nakamoto.
        Although the blockchain technology is older than Bitcoin, it is a core underlying component of most
        cryptocurrency networks, acting as a decentralized, distributed and public digital ledger that is responsible
        for keeping a permanent record (chain of blocks) of all previously confirmed transactions.

        Blockchain transactions occur within a peer-to-peer network of globally distributed computers (nodes). Each node
        maintains a copy of the blockchain and contributes to the functioning and security of the network. This is what
        makes Bitcoin a decentralized digital currency that is borderless, censorship-resistant, and that does not
        require third-party intermediation.
        As a distributed ledger technology (DLT) the blockchain is intentionally designed to be highly resistant to
        modification and frauds (such as double-spending). This is true because the Bitcoin blockchain, as a database of
        records, cannot be altered, nor can it be tampered without an impractical amount of electricity and
        computational power - which means the network can enforce the concept of "original" digital documents, making
        each Bitcoin a very unique and un-copyable form of digital currency.


    <h2 id="cc">Cloud Computing</h2>
    <p>
        Cloud computing is on-demand access, via the internet, to computing resources—applications, servers (physical
        servers and virtual servers), data storage, development tools, networking capabilities, and more—hosted at a
        remote data center managed by a cloud services provider (or CSP). The CSP makes these resources available for a
        monthly subscription fee or bills them according to usage.

        Compared to traditional on-premises IT, and depending on the cloud services you select, cloud computing helps do
        the following:

        Lower IT costs: Cloud lets you offload some or most of the costs and effort of purchasing, installing,
        configuring, and managing your own on-premises infrastructure.

        Improve agility and time-to-value: With cloud, your organization can start using enterprise applications in
        minutes, instead of waiting weeks or months for IT to respond to a request, purchase and configure supporting
        hardware, and install software. Cloud also lets you empower certain users—specifically developers and data
        scientists—to help themselves to software and support infrastructure.

        Scale more easily and cost-effectively: Cloud provides elasticity—instead of purchasing excess capacity that
        sits unused during slow periods, you can scale capacity up and down in response to spikes and dips in traffic.
        You can also take advantage of your cloud providers global network to spread your applications closer to users
        around the world.
        The term cloud computing also refers to the technology that makes cloud work. This includes some form of
        virtualized IT infrastructure—servers, operating system software, networking, and other infrastructure thats
        abstracted, using special software, so that it can be pooled and divided irrespective of physical hardware
        boundaries. For example, a single hardware server can be divided into multiple virtual servers.

        Virtualization enables cloud providers to make maximum use of their data center resources. Not surprisingly,
        many corporations have adopted the cloud delivery model for their on-premises infrastructure so they can realize
        maximum utilization and cost savings vs. traditional IT infrastructure and offer the same self-service and
        agility to their end-users.

        If you use a computer or mobile device at home or at work, you almost certainly use some form of cloud computing
        every day, whether its a cloud application like Google Gmail or Salesforce, streaming media like Netflix, or
        cloud file storage like Dropbox. Industry analyst Gartner projected recently that worldwide end-user public
        cloud spending to reach nearly USD 600 billion in 2023 (link resides outside ibm.com).


    </p>
    <h2 id="iot">Internet Of Things</h2>
    <p>
        The internet of things, or IoT, is a network of interrelated devices that connect and exchange data with other
        IoT devices and the cloud. IoT devices are typically embedded with technology such as sensors and software and
        can include mechanical and digital machines and consumer objects.

        Increasingly, organizations in a variety of industries are using IoT to operate more efficiently, deliver
        enhanced customer service, improve decision-making and increase the value of the business.

        With IoT, data is transferable over a network without requiring human-to-human or human-to-computer
        interactions.

        A thing in the internet of things can be a person with a heart monitor implant, a farm animal with a biochip
        transponder, an automobile that has built-in sensors to alert the driver when tire pressure is low, or any other
        natural or man-made object that can be assigned an Internet Protocol address and is able to transfer data over a
        network.

        How does IoT work?
        An IoT ecosystem consists of web-enabled smart devices that use embedded systems -- such as processors, sensors
        and communication hardware -- to collect, send and act on data they acquire from their environments.
    </p>
    <h2 id="meta">MetaVerse</h2>
    <p>
        Meta defines the metaverse as “the next evolution in social connection and the successor to the mobile
        internet.”

        While this definition is generally true, it’s important to know that Meta doesn’t control the metaverse; no
        company does.In fact, rather than thinking of one virtual space called the metaverse, it’s more appropriate to
        use the plural form, metaverses, at the current stage.

        A metaverse can be any 3D virtual space powered by technologies – including virtual reality (VR), augmented
        reality (AR), artificial intelligence (AI), the Internet of Things (IoT), and blockchain – that allows people to
        interact with each other (and in some cases, with non-human avatars).

        There are many metaverses existing today.

        Most of them were created by individual companies and serve a particular purpose. There is little to no
        interoperability among metaverses, as the standards of sharing user identities and data across different
        metaverse spaces haven’t been developed yet.The term “metaverse” was first used by sci-fi writer Neal Stephenson
        in his 1992 novel “Snow Crash.” In the novel, Mr. Stephenson describes a 3D virtual world that people could, in
        a sense, occupy.

        The novel’s main character, Hiro, accesses the metaverse via a personal terminal that projects 3D virtual
        reality images to his goggles. Hiro’s avatar interacts with other people’s avatars in the metaverse, and in
        fact, “Snow Crash” is the name of a data file Hiro’s avatar received in the metaverse.

        Fiction aside, digital gaming is how the metaverse was introduced to and adapted by consumers in scale. Launched
        in 2016, Pokémon Go, which incorporated augmented reality into mobile gaming, took the world by storm.

    </p>
</body>

</html>